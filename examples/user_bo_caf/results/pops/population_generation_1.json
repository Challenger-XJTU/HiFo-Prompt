[
     {
          "algorithm": "```",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train, dim = train_x.shape\n    n_test = test_x.shape[0]\n    \n    # Compute normalized remaining budget\n    remaining_budget = (budget_total - budget_used) / budget_total\n    \n    # Simplified exploration term: directly scale by remaining budget\n    exploration_term = std_test_y * remaining_budget\n    \n    # Simplified exploitation term: focus on predicted mean and penalize distance to best solution\n    distance_to_best = torch.norm(test_x - best_x, dim=1)\n    exploitation_term = mean_test_y / (1 + distance_to_best)\n    \n    # Simplified cost penalty: emphasize cost efficiency as budget decreases\n    cost_penalty = cost_test_y * (1 - remaining_budget)\n    \n    # Combine terms into utility function with equal weighting\n    utility_value = exploitation_term + exploration_term - cost_penalty\n    \n    return utility_value",
          "objective": 3.66957,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Dynamically adjust the exploration-exploitation tradeoff by incorporating cost-aware budget allocation and historical performance feedback to optimize resource utilization.",
                    "Integrate adaptive objective transformations and diversification strategies to systematically target underexplored regions while maintaining a balance between search efficiency and solution quality.",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "investigating alternative problem decomposition approaches",
               "generation_tendency": "focus_exploration",
               "timestamp": 1752308875.232694
          }
     },
     {
          "algorithm": "The algorithm computes utility by combining predictive mean and standard deviation of unobserved inputs with cost-aware budget allocation, dynamically adjusting exploration-exploitation tradeoff based on remaining budget and historical performance patterns.",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train, dim = train_x.shape\n    n_test = test_x.shape[0]\n    \n    # Compute normalized remaining budget\n    remaining_budget = (budget_total - budget_used) / budget_total\n    \n    # Scale exploration term by remaining budget to encourage exploitation as budget dwindles\n    exploration_term = std_test_y * remaining_budget\n    \n    # Scale exploitation term by distance to the current best solution in input space\n    distance_to_best = torch.norm(test_x - best_x, dim=1)\n    scaled_distance = 1 / (1 + distance_to_best)  # Inverse distance for exploitation bias\n    exploitation_term = mean_test_y * scaled_distance\n    \n    # Cost penalty: penalize high-cost evaluations more aggressively as budget decreases\n    cost_penalty = cost_test_y / (1 + remaining_budget)\n    \n    # Combine terms into utility function\n    utility_value = exploitation_term + exploration_term - cost_penalty\n    \n    return utility_value",
          "objective": 4.74029,
          "other_inf": null,
          "metadata": {
               "operator": "i1",
               "wisdom_tips": [
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration"
               ],
               "attention_focus": "managing computational complexity and time efficiency",
               "generation_tendency": "balanced_search",
               "timestamp": 1752306752.723721
          }
     },
     {
          "algorithm": "```",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train = train_x.size(0)\n    n_test = test_x.size(0)\n\n    # Adaptive objective transformation: amplify distinctions in promising regions\n    scaled_mean = torch.log1p(mean_test_y - torch.min(train_y) + 1e-8)\n\n    # Cost-aware budget allocation: prioritize low-cost evaluations with diminishing returns\n    remaining_budget_ratio = (budget_total - budget_used) / (budget_total + 1e-8)\n    cost_efficiency = torch.exp(-cost_test_y / (torch.mean(cost_test_y) + 1e-8)) * remaining_budget_ratio\n\n    # Uncertainty modulation: scale uncertainty by feature-space density\n    knn_distances = torch.cdist(test_x, train_x)\n    avg_knn_distance = torch.mean(knn_distances, dim=1)\n    modulated_uncertainty = std_test_y / (avg_knn_distance + 1e-8)\n\n    # Combine terms into the utility function with dynamic weighting\n    exploration_weight = 1.0 - remaining_budget_ratio  # Increase exploration as budget decreases\n    exploitation_weight = remaining_budget_ratio       # Focus on exploitation early on\n\n    utility_value = (\n        exploitation_weight * scaled_mean +\n        exploration_weight * modulated_uncertainty +\n        cost_efficiency\n    )\n\n    return utility_value",
          "objective": 5.94262,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Dynamically adjust the exploration-exploitation tradeoff by incorporating cost-aware budget allocation and historical performance feedback to optimize resource utilization.",
                    "Integrate adaptive objective transformations and diversification strategies to systematically target underexplored regions while maintaining a balance between search efficiency and solution quality.",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "investigating alternative problem decomposition approaches",
               "generation_tendency": "focus_exploration",
               "timestamp": 1752308815.154881
          }
     },
     {
          "algorithm": "Propose a utility function that dynamically reshapes the search landscape by integrating an adaptive objective transformation, feature-space guided diversification, and cost-aware budget allocation to balance exploration-exploitation while systematically targeting underexplored regions.",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train = train_x.size(0)\n    dim = train_x.size(1)\n    n_test = test_x.size(0)\n\n    # Adaptive objective transformation: reshape the predictive mean to amplify distinctions in promising regions\n    scaled_mean = torch.log1p(mean_test_y - torch.min(train_y) + 1e-8)\n\n    # Feature-space guided diversification: compute normalized distance to training data centroid\n    train_centroid = torch.mean(train_x, dim=0)\n    dist_to_centroid = torch.norm(test_x - train_centroid.unsqueeze(0), dim=1)\n    max_dist = torch.max(torch.norm(train_x - train_centroid.unsqueeze(0), dim=1))\n    normalized_diversity = dist_to_centroid / (max_dist + 1e-8)\n\n    # Cost-aware budget allocation: prioritize low-cost evaluations with diminishing returns as budget depletes\n    remaining_budget_ratio = (budget_total - budget_used) / (budget_total + 1e-8)\n    cost_efficiency = torch.exp(-cost_test_y / (torch.mean(cost_test_y) + 1e-8)) * remaining_budget_ratio\n\n    # Uncertainty modulation: scale uncertainty by the inverse of feature-space density around the test point\n    knn_distances = torch.cdist(test_x, train_x)\n    avg_knn_distance = torch.mean(knn_distances, dim=1)\n    modulated_uncertainty = std_test_y / (avg_knn_distance + 1e-8)\n\n    # Combine terms into the utility function with dynamic weighting based on search progress\n    exploration_weight = 1.0 - remaining_budget_ratio  # Increase exploration as budget decreases\n    exploitation_weight = remaining_budget_ratio      # Focus on exploitation early on\n\n    utility_value = (\n        exploitation_weight * scaled_mean +\n        exploration_weight * modulated_uncertainty +\n        normalized_diversity * cost_efficiency\n    )\n\n    return utility_value",
          "objective": 6.30816,
          "other_inf": null,
          "metadata": {
               "operator": "e1",
               "wisdom_tips": [
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "optimizing objective function evaluation criteria",
               "generation_tendency": "balanced_search",
               "timestamp": 1752307410.207055
          }
     },
     {
          "algorithm": "```",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train, dim = train_x.shape\n    n_test = test_x.shape[0]\n    \n    # Compute normalized remaining budget\n    remaining_budget = (budget_total - budget_used) / budget_total\n    \n    # Hybrid exploration-exploitation term with dynamic scaling\n    exploration_term = std_test_y * remaining_budget\n    distance_to_best = torch.norm(test_x - best_x, dim=1)\n    exploitation_term = mean_test_y / (1 + distance_to_best)\n    hybrid_term = exploration_term + exploitation_term\n    \n    # Cost-aware penalty with adaptive scaling\n    cost_penalty = cost_test_y * (1 + 1 / (1 + remaining_budget))\n    \n    # Combine terms into simplified utility function\n    utility_value = hybrid_term - cost_penalty\n    \n    return utility_value",
          "objective": 6.64905,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Dynamically adjust the exploration-exploitation tradeoff by incorporating cost-aware budget allocation and historical performance feedback to optimize resource utilization.",
                    "Integrate adaptive objective transformations and diversification strategies to systematically target underexplored regions while maintaining a balance between search efficiency and solution quality.",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1752308950.324689
          }
     },
     {
          "algorithm": "A modified utility algorithm that emphasizes adaptive cost-aware diversification and fine-tuned exploitation-exploration balance by introducing a dynamic threshold mechanism and enhanced restart incentives.",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    # Compute normalized distance to the best solution in feature space\n    dist_to_best = torch.norm(test_x - best_x, dim=1)\n    max_train_dist = torch.max(torch.cdist(train_x, train_x)).item()\n    normalized_dist = dist_to_best / max_train_dist\n    \n    # Dynamic threshold for exploitation based on remaining budget\n    remaining_budget_ratio = (budget_total - budget_used) / budget_total\n    exploitation_threshold = 0.5 + 0.5 * remaining_budget_ratio  # Adaptive threshold\n    \n    # Scale exploitation by improvement potential over the best solution with thresholding\n    improvement_potential = torch.clamp(mean_test_y - best_y, min=0)\n    exploitation_term = improvement_potential * torch.sigmoid(exploitation_threshold - normalized_dist)\n    \n    # Enhanced restart term based on feature gaps and diversity promotion\n    feature_gaps = torch.mean(torch.cdist(test_x.unsqueeze(1), train_x.unsqueeze(0)), dim=2).min(dim=1).values\n    restart_term = torch.exp(-feature_gaps) * (1 + remaining_budget_ratio)  # Amplified exploration of uncovered regions\n    \n    # Scale exploration by uncertainty and dynamic restart incentives\n    exploration_term = std_test_y * restart_term * remaining_budget_ratio\n    \n    # Penalize high-cost evaluations with budget-aware scaling and fine-tuned sensitivity\n    avg_cost = torch.mean(cost_test_y)\n    cost_sensitivity = 1.0 + 0.5 * remaining_budget_ratio  # Fine-tuned sensitivity parameter\n    cost_penalty = torch.log1p(cost_test_y / avg_cost) ** cost_sensitivity\n    \n    # Combine terms into the utility function with refined balancing\n    utility_value = (exploitation_term + exploration_term) / (1 + cost_penalty)\n    \n    return utility_value",
          "objective": 7.36237,
          "other_inf": null,
          "metadata": {
               "operator": "m1",
               "wisdom_tips": [
                    "Integrate cost-aware strategies that allocate resources efficiently while accounting for both predictive accuracy and variability in unobserved outcomes.",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "fine-tuning critical algorithm parameters and thresholds",
               "generation_tendency": "focus_exploitation",
               "timestamp": 1752308057.852801
          }
     },
     {
          "algorithm": "Propose a utility function that integrates randomized adaptive weighting, cost-penalized exploration, and predictive confidence modulation to dynamically balance resource allocation and solution quality in high-dimensional search spaces.",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    n_train = train_x.size(0)\n    dim = train_x.size(1)\n    n_test = test_x.size(0)\n\n    # Randomized adaptive weighting: introduce stochasticity in exploitation-exploration trade-off\n    random_factor = torch.rand(1, dtype=torch.float64)  # Random factor for dynamic weighting\n    exploration_weight = random_factor * (budget_used / (budget_total + 1e-8))\n    exploitation_weight = 1.0 - exploration_weight\n\n    # Cost-penalized exploration: prioritize regions with lower costs and higher uncertainty\n    cost_penalty = torch.log1p(cost_test_y / (torch.mean(cost_test_y) + 1e-8))\n    penalized_uncertainty = std_test_y / (cost_penalty + 1e-8)\n\n    # Predictive confidence modulation: scale mean predictions by inverse density around test points\n    knn_distances = torch.cdist(test_x, train_x)\n    avg_knn_distance = torch.mean(knn_distances, dim=1)\n    confidence_modulated_mean = mean_test_y / (avg_knn_distance + 1e-8)\n\n    # Adaptive normalization of diversity: emphasize underexplored regions in feature space\n    train_centroid = torch.mean(train_x, dim=0)\n    dist_to_centroid = torch.norm(test_x - train_centroid.unsqueeze(0), dim=1)\n    normalized_diversity = torch.sigmoid(dist_to_centroid - torch.mean(dist_to_centroid))\n\n    # Combine terms into the utility function with randomized and cost-aware adjustments\n    utility_value = (\n        exploitation_weight * confidence_modulated_mean +\n        exploration_weight * penalized_uncertainty +\n        normalized_diversity * torch.exp(-cost_penalty)\n    )\n\n    return utility_value",
          "objective": 7.64928,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Integrate cost-awareness into utility computations to ensure efficient allocation of resources while pursuing high-reward solutions.",
                    "Integrate cost-aware strategies that allocate resources efficiently while accounting for both predictive accuracy and variability in unobserved outcomes.",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration"
               ],
               "attention_focus": "introducing new randomization or adaptive mechanisms",
               "generation_tendency": "focus_exploration",
               "timestamp": 1752308332.641663
          }
     },
     {
          "algorithm": "```",
          "code": "import torch\n\ndef utility(train_x, train_y, best_x, best_y, test_x, mean_test_y, std_test_y, cost_test_y, budget_used, budget_total):\n    # Compute normalized distance to the best solution in feature space\n    dist_to_best = torch.norm(test_x - best_x, dim=1)\n    max_train_dist = torch.max(torch.cdist(train_x, train_x)).item()\n    normalized_dist = dist_to_best / max_train_dist\n    \n    # Encourage exploration of uncovered regions with a simplified restart term\n    min_feature_gap = torch.min(torch.cdist(test_x.unsqueeze(1), train_x.unsqueeze(0)), dim=2).values.mean(dim=1)\n    restart_term = torch.exp(-min_feature_gap)\n    \n    # Scale exploitation by improvement potential over the best solution\n    improvement_potential = torch.clamp(mean_test_y - best_y, min=0)\n    exploitation_term = improvement_potential * (1 - normalized_dist)\n    \n    # Scale exploration by uncertainty and remaining budget\n    remaining_budget_ratio = (budget_total - budget_used) / budget_total\n    exploration_term = std_test_y * remaining_budget_ratio * restart_term\n    \n    # Penalize high-cost evaluations dynamically with budget-aware scaling\n    cost_penalty = torch.log1p(cost_test_y / torch.mean(cost_test_y)) * (1 + remaining_budget_ratio)\n    \n    # Combine terms into the utility function\n    utility_value = (exploitation_term + exploration_term) / (1 + cost_penalty)\n    \n    return utility_value",
          "objective": 8.43575,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Dynamically adjust the exploration-exploitation tradeoff by incorporating cost-aware budget allocation and historical performance feedback to optimize resource utilization.",
                    "Integrate adaptive objective transformations and diversification strategies to systematically target underexplored regions while maintaining a balance between search efficiency and solution quality.",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "exploring novel solution construction methodologies",
               "generation_tendency": "focus_exploration",
               "timestamp": 1752309070.7609012
          }
     }
]