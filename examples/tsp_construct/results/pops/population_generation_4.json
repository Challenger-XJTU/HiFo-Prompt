[
     {
          "algorithm": "The new algorithm incrementally selects the next node by prioritizing candidates based on a hybrid scoring function combining normalized edge costs, momentum-based trajectory alignment, MST-based global connectivity, and Monte Carlo-inspired lookahead simulations with adaptive weighting tuned for early exploration and late exploitation.}\n\n```python\nimport numpy as np\nfrom heapq import heappush, heappop\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes",
          "code": "import numpy as np\nfrom heapq import heappush, heappop\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    priority_queue = []\n    adaptive_weight = np.random.uniform(0.6, 1.4)\n    median_distance = np.median(distance_matrix[current_node])\n    \n    for candidate in unvisited_nodes:\n        direct_cost = distance_matrix[current_node][candidate]\n        look_ahead_cost = lookahead_simulation(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = direct_cost / (median_distance + 1e-6)\n        momentum_bonus = 0.5 * (1 - direct_cost / max(distance_matrix[current_node]))\n        hybrid_score = (adaptive_weight * look_ahead_cost) + (0.9 * mst_remaining) + (0.3 * normalized_cost) - momentum_bonus\n        heappush(priority_queue, (hybrid_score, candidate))\n    \n    next_node = heappop(priority_queue)[1]\n    return next_node",
          "objective": 5.98521,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Use incremental, greedy decisions to build solutions while preserving global constraints through efficient data structures (e.g., union-find for connectivity tracking).",
                    "Leverage heuristic-guided exploration to efficiently evaluate candidate choices, focusing on a subset of high-potential options to balance computational cost and solution quality.",
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "balanced_search",
               "timestamp": 1758182841.285204
          }
     },
     {
          "algorithm": "A new algorithm that dynamically adjusts weights for look-ahead cost, minimum spanning tree influence, and normalized edge costs with a focus on long-term path quality and diversity exploration.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.8, 1.2)  # Adjusted adaptive randomization range\n    for candidate in candidates:\n        look_ahead_cost = evaluate_candidate(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = distance_matrix[current_node][candidate] / (np.median(distance_matrix[current_node]) + 1e-6)\n        scores[candidate] = (adaptive_weight * look_ahead_cost) + (0.8 * mst_remaining) + (0.3 * normalized_cost)\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.04347,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "considering long-term impact of current decisions",
               "generation_tendency": "balanced_search",
               "timestamp": 1758183148.622241
          }
     },
     {
          "algorithm": "The algorithm selects the next node by dynamically adjusting candidate thresholds, incorporating path momentum and clustering tendencies, and blending MST-based global cost modeling with adaptive lookahead simulations while using fine-tuned hybrid scoring weights.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.9, 1.1)\n    momentum_weight = np.random.uniform(0.2, 0.4)\n    clustering_weight = np.random.uniform(0.3, 0.5)\n    \n    for candidate in candidates:\n        direct_cost = distance_matrix[current_node][candidate]\n        look_ahead_cost = lookahead_simulation(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = direct_cost / (np.median(distance_matrix[current_node]) + 1e-6)\n        momentum_bonus = momentum_weight * (1 - distance_matrix[current_node][candidate] / max(distance_matrix[current_node]))\n        clustering_bonus = clustering_weight * (1 - len(candidates) / max(len(unvisited_nodes), 1))\n        scores[candidate] = (adaptive_weight * look_ahead_cost) + (0.8 * mst_remaining) + (0.6 * normalized_cost) - momentum_bonus + clustering_bonus\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.05127,
          "other_inf": null,
          "metadata": {
               "operator": "m1",
               "wisdom_tips": [
                    "Combine short-term decision metrics with long-term strategic evaluations to guide incremental progress effectively.",
                    "Use hybrid scoring functions that integrate multiple heuristic signals to balance exploration and exploitation dynamically.",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "fine-tuning critical algorithm parameters and thresholds",
               "generation_tendency": "focus_exploitation",
               "timestamp": 1758183076.791193
          }
     },
     {
          "algorithm": "The algorithm selects the next node by blending adaptive lookahead simulations, MST-based global planning, and a hybrid scoring function that integrates momentum-aware penalties, cost normalization, and cluster density awareness while dynamically adjusting weights for exploration-exploitation balance.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    def cluster_density(node):\n        nearest_neighbors = sorted(unvisited_nodes, key=lambda x: distance_matrix[node][x])[:3]\n        return np.mean([distance_matrix[node][n] for n in nearest_neighbors])\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    def cluster_density(node):\n        nearest_neighbors = sorted(unvisited_nodes, key=lambda x: distance_matrix[node][x])[:3]\n        return np.mean([distance_matrix[node][n] for n in nearest_neighbors])\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.7, 1.3)\n    for candidate in candidates:\n        direct_cost = distance_matrix[current_node][candidate]\n        look_ahead_cost = lookahead_simulation(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = direct_cost / (np.median(distance_matrix[current_node]) + 1e-6)\n        momentum_penalty = 0.4 * (distance_matrix[current_node][candidate] / max(distance_matrix[current_node]))\n        density_bonus = 0.2 * (1 - cluster_density(candidate) / max(distance_matrix[current_node]))\n        scores[candidate] = (\n            adaptive_weight * look_ahead_cost +\n            0.6 * mst_remaining +\n            0.4 * normalized_cost -\n            momentum_penalty +\n            density_bonus\n        )\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.05214,
          "other_inf": null,
          "metadata": {
               "operator": "m1",
               "wisdom_tips": [
                    "Combine short-term decision metrics with long-term strategic evaluations to guide incremental progress effectively.",
                    "Use hybrid scoring functions that integrate multiple heuristic signals to balance exploration and exploitation dynamically.",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "refining core evaluation and scoring functions",
               "generation_tendency": "balanced_search",
               "timestamp": 1758183113.768739
          }
     },
     {
          "algorithm": "The new algorithm blends adaptive lookahead simulations, MST-based global planning, and a refined hybrid scoring function emphasizing dynamic exploration-exploitation balance, surrogate objectives, and feature-aware diversification strategies.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    def cluster_density(node):\n        nearest_neighbors = sorted(unvisited_nodes, key=lambda x: distance_matrix[node][x])[:3]\n        return np.mean([distance_matrix[node][n] for n in nearest_neighbors])\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def lookahead_simulation(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    def cluster_density(node):\n        nearest_neighbors = sorted(unvisited_nodes, key=lambda x: distance_matrix[node][x])[:3]\n        return np.mean([distance_matrix[node][n] for n in nearest_neighbors])\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.8, 1.2)\n    for candidate in candidates:\n        direct_cost = distance_matrix[current_node][candidate]\n        look_ahead_cost = lookahead_simulation(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = direct_cost / (np.median(distance_matrix[current_node]) + 1e-6)\n        momentum_penalty = 0.3 * (distance_matrix[current_node][candidate] / max(distance_matrix[current_node]))\n        density_bonus = 0.3 * (1 - cluster_density(candidate) / max(distance_matrix[current_node]))\n        surrogate_objective = 0.1 * (len(unvisited_nodes) / max(distance_matrix[current_node]))  # Encourage diversity\n        scores[candidate] = (\n            adaptive_weight * look_ahead_cost +\n            0.7 * mst_remaining +\n            0.5 * normalized_cost -\n            momentum_penalty +\n            density_bonus +\n            surrogate_objective\n        )\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.05216,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "refining core evaluation and scoring functions",
               "generation_tendency": "focus_exploitation",
               "timestamp": 1758183148.644508
          }
     },
     {
          "algorithm": "A new algorithm that uses hybrid strategy combinations by introducing adaptive weights for look-ahead evaluation, MST-based connectivity cost, and normalized edge costs while incorporating a diversification mechanism based on solution feature analysis.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(5, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.5, 1.5)  # Adjusted range for exploration\n    diversification_factor = np.std([distance_matrix[current_node][n] for n in unvisited_nodes]) + 1e-6\n    for candidate in candidates:\n        look_ahead_cost = evaluate_candidate(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = distance_matrix[current_node][candidate] / (np.mean(distance_matrix[current_node]) + 1e-6)\n        feature_diversity = np.abs(distance_matrix[current_node][candidate] - diversification_factor)\n        scores[candidate] = (adaptive_weight * look_ahead_cost) + (0.8 * mst_remaining) + (0.3 * normalized_cost) + (0.2 * feature_diversity)\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.05684,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1758183194.152042
          }
     },
     {
          "algorithm": "node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(3, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(3, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = np.random.uniform(0.7, 1.3)  # Reduced range for stability\n    for candidate in candidates:\n        look_ahead_cost = evaluate_candidate(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = distance_matrix[current_node][candidate] / (np.median(distance_matrix[current_node]) + 1e-6)\n        scores[candidate] = (adaptive_weight * look_ahead_cost) + (0.6 * mst_remaining) + (0.4 * normalized_cost)\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.07493,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Combine structural insights (e.g., MST-based cost modeling) with greedy heuristics to guide decision-making while preserving global solution quality.",
                    "Dynamically balance exploration of new options and exploitation of known good choices through adaptive weighting and lookahead simulations.",
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features"
               ],
               "attention_focus": "exploring novel solution construction methodologies",
               "generation_tendency": "balanced_search",
               "timestamp": 1758182497.993067
          }
     },
     {
          "algorithm": "node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(3, len(unvisited_nodes))]\n    scores = {",
          "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def mst_cost(nodes):\n        if len(nodes) <= 1:\n            return 0\n        edges = sorted([(distance_matrix[i][j], i, j) for i in nodes for j in nodes if i < j], key=lambda x: x[0])\n        parent = {node: node for node in nodes}\n        \n        def find(node):\n            while parent[node] != node:\n                parent[node] = parent[parent[node]]\n                node = parent[node]\n            return node\n        \n        def union(node1, node2):\n            root1 = find(node1)\n            root2 = find(node2)\n            if root1 != root2:\n                parent[root2] = root1\n        \n        total_cost = 0\n        for cost, u, v in edges:\n            if find(u) != find(v):\n                union(u, v)\n                total_cost += cost\n        return total_cost\n    \n    def evaluate_candidate(node):\n        remaining_nodes = list(unvisited_nodes)\n        remaining_nodes.remove(node)\n        path = [current_node, node]\n        while remaining_nodes:\n            next_step = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n            path.append(next_step)\n            remaining_nodes.remove(next_step)\n        return sum(distance_matrix[path[i]][path[i+1]] for i in range(len(path)-1))\n    \n    candidates = sorted(unvisited_nodes, key=lambda x: distance_matrix[current_node][x])[:min(3, len(unvisited_nodes))]\n    scores = {}\n    adaptive_weight = 1.0  # Fixed weight for stability\n    for candidate in candidates:\n        look_ahead_cost = evaluate_candidate(candidate)\n        mst_remaining = mst_cost([destination_node] + [n for n in unvisited_nodes if n != candidate])\n        normalized_cost = distance_matrix[current_node][candidate] / (np.mean(distance_matrix[current_node]) + 1e-6)\n        scores[candidate] = (adaptive_weight * look_ahead_cost) + (0.7 * mst_remaining) + (0.4 * normalized_cost)\n    \n    next_node = min(scores, key=scores.get)\n    return next_node",
          "objective": 6.07827,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration",
                    "Construct problem specialized efficient solution representations and co design dedicated core operators to fully leverage representation structure for powerful solution space exploration",
                    "Implement intelligent diversification and restart strategies based on solution feature space analysis systematically targeting uncovered feature regions to promote global search coverage and escape deep local optima"
               ],
               "attention_focus": "investigating alternative problem decomposition approaches",
               "generation_tendency": "balanced_search",
               "timestamp": 1758183264.224392
          }
     }
]