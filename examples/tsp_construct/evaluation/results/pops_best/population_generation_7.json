{
     "algorithm": "The algorithm selects the next node by adaptively balancing edge cost normalization, global coherence via minimum spanning tree approximation, and Monte Carlo-guided look-ahead evaluations, emphasizing diverse path exploration with reduced computational overhead.}\n\n```python\nimport numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def monte_carlo_rollout(node, candidates, simulations=20):\n        scores = {candidate: 0 for candidate in candidates}\n        for _ in range(simulations):\n            for candidate in candidates:\n                remaining_nodes = [n for n in unvisited_nodes if n != candidate]\n                path = [current_node, candidate]\n                total_cost = distance_matrix[current_node][candidate]\n                while remaining_nodes:\n                    next_node = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n                    path.append(next_node)\n                    total_cost += distance_matrix[path[-2]][path[-1]]\n                    remaining_nodes.remove(next_node)\n                total_cost += distance_matrix[path[-1]][destination_node]\n                scores[candidate] += total_cost\n        return {k: v / simulations for k, v in scores.items()}\n    \n    def mst_approximation_cost(candidate):\n        edges = sorted([(distance_matrix[current_node][x], x) for x in unvisited_nodes if x != candidate])\n        return sum(cost for cost, _ in edges[:min(3, len(edges))])\n    \n    # Step 1: Generate a limited candidate set based on nearest neighbors\n    all_candidates = unvisited_nodes\n    candidate_set_size = min(10, len(all_candidates))  # Reduced candidate set size\n    candidates = sorted(all_candidates, key=lambda x: distance_matrix[current_node][x])[:candidate_set_size]\n    \n    # Step 2: Perform Monte Carlo-like rollouts to evaluate candidates\n    rollout_scores = monte_carlo_rollout(current_node, candidates)\n    \n    # Step 3: Approximate global coherence using MST properties\n    mst_scores = {candidate: mst_approximation_cost(candidate) for candidate in candidates}\n    \n    # Step 4: Dynamically weight local edge costs, Monte Carlo scores, and MST coherence\n    weighted_scores = {\n        candidate: (0.5 * distance_matrix[current_node][candidate] + \n                    0.3 * rollout_scores[candidate] + \n                    0.2 * mst_scores[candidate]) / \n                   (1 + 0.15 * np.std([distance_matrix[current_node][x] for x in unvisited_nodes]))\n        for candidate in candidates\n    ",
     "code": "import numpy as np\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    def monte_carlo_rollout(node, candidates, simulations=20):\n        scores = {candidate: 0 for candidate in candidates}\n        for _ in range(simulations):\n            for candidate in candidates:\n                remaining_nodes = [n for n in unvisited_nodes if n != candidate]\n                path = [current_node, candidate]\n                total_cost = distance_matrix[current_node][candidate]\n                while remaining_nodes:\n                    next_node = min(remaining_nodes, key=lambda x: distance_matrix[path[-1]][x])\n                    path.append(next_node)\n                    total_cost += distance_matrix[path[-2]][path[-1]]\n                    remaining_nodes.remove(next_node)\n                total_cost += distance_matrix[path[-1]][destination_node]\n                scores[candidate] += total_cost\n        return {k: v / simulations for k, v in scores.items()}\n    \n    def mst_approximation_cost(candidate):\n        edges = sorted([(distance_matrix[current_node][x], x) for x in unvisited_nodes if x != candidate])\n        return sum(cost for cost, _ in edges[:min(3, len(edges))])\n    \n    # Step 1: Generate a limited candidate set based on nearest neighbors\n    all_candidates = unvisited_nodes\n    candidate_set_size = min(10, len(all_candidates))  # Reduced candidate set size\n    candidates = sorted(all_candidates, key=lambda x: distance_matrix[current_node][x])[:candidate_set_size]\n    \n    # Step 2: Perform Monte Carlo-like rollouts to evaluate candidates\n    rollout_scores = monte_carlo_rollout(current_node, candidates)\n    \n    # Step 3: Approximate global coherence using MST properties\n    mst_scores = {candidate: mst_approximation_cost(candidate) for candidate in candidates}\n    \n    # Step 4: Dynamically weight local edge costs, Monte Carlo scores, and MST coherence\n    weighted_scores = {\n        candidate: (0.5 * distance_matrix[current_node][candidate] + \n                    0.3 * rollout_scores[candidate] + \n                    0.2 * mst_scores[candidate]) / \n                   (1 + 0.15 * np.std([distance_matrix[current_node][x] for x in unvisited_nodes]))\n        for candidate in candidates\n    }\n    \n    # Step 5: Select the next node with the lowest weighted score\n    next_node = min(weighted_scores, key=weighted_scores.get)\n    \n    return next_node",
     "objective": 5.95025,
     "other_inf": null,
     "metadata": {
          "operator": "m2",
          "wisdom_tips": [
               "Balance local optimization with global solution structure when making decisions",
               "Use dynamic weighting mechanisms to adapt algorithm behavior based on current state",
               "Consider the impact of current choices on future decision flexibility"
          ],
          "attention_focus": "reducing unnecessary computational overhead and redundancy",
          "generation_tendency": "balanced_search",
          "timestamp": 1748280867.460076
     }
}