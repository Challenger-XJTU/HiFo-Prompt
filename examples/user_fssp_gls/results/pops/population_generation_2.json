[
     {
          "algorithm": "A hybrid algorithm adaptively perturbs jobs and updates the execution time matrix by combining machine learning-driven job prioritization, dynamic objective weighting, and local search enhancement to escape local optima and minimize makespan.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            machine_times[0] += matrix[job][0]\n            for i in range(1, m):\n                machine_times[i] = max(machine_times[i], machine_times[i-1]) + matrix[job][i]\n        return machine_times[-1]\n\n    # Calculate current makespan\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n\n    # Perturb jobs using a hybrid approach\n    perturb_jobs = []\n    new_matrix = time_matrix.copy()\n\n    # Step 1: Identify critical jobs contributing most to makespan\n    job_contributions = []\n    for job in current_sequence:\n        temp_sequence = current_sequence.copy()\n        temp_sequence.remove(job)\n        reduced_makespan = calculate_makespan(temp_sequence, time_matrix, m)\n        contribution = current_makespan - reduced_makespan\n        job_contributions.append((job, contribution))\n    \n    # Sort jobs by their contribution (descending order)\n    job_contributions.sort(key=lambda x: x[1], reverse=True)\n    perturb_jobs = [job for job, _ in job_contributions[:max(1, n // 4)]]\n\n    # Step 2: Dynamically adjust execution times for perturbed jobs\n    for job in perturb_jobs:\n        for machine in range(m):\n            new_matrix[job][machine] *= np.random.uniform(0.9, 1.1)  # Slight perturbation\n\n    # Step 3: Introduce auxiliary objectives to reshape search landscape\n    # Example: Penalize high variance in machine loads\n    machine_loads = [sum(time_matrix[job][i] for job in current_sequence) for i in range(m)]\n    load_variance = np.var(machine_loads)\n    if load_variance > np.mean(machine_loads):  # High variance detected\n        for job in perturb_jobs:\n            for machine in range(m):\n                new_matrix[job][machine] *= np.random.uniform(0.85, 1.15)  # Stronger perturbation\n\n    return new_matrix, perturb_jobs",
          "objective": 3483.0,
          "other_inf": null,
          "metadata": {
               "operator": "i1",
               "wisdom_tips": [
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features",
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "improving algorithm robustness across different problem instances",
               "generation_tendency": "balanced_search",
               "timestamp": 1757944831.997516
          }
     },
     {
          "algorithm": "The algorithm integrates machine learning-driven prioritization with dynamic objective weighting to update the execution time matrix using a hybrid strategy combining makespan minimization and load balance improvement, while selecting jobs for perturbation based on adaptive dual-objective scoring with non-linear weighting.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_load_balance(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        avg_load = sum(machine_times) / m\n        return sum((t - avg_load)**2 for t in machine_times)\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_contributions = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_contributions[job] += machine_times[machine]**2  # Quadratic emphasis on contributions\n        return np.argsort(-job_contributions)[:n//3]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            noise = np.random.uniform(-0.05, 0.1, size=m)  # Uniform perturbation with asymmetric bounds\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and load balance metric\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    load_balance_metric = calculate_load_balance(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs contributing to bottlenecks\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix with uniform perturbation\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb based on adaptive dual-objective scoring\n    dual_scores = (np.sum(new_matrix[critical_jobs, :], axis=1) ** 1.5) + (load_balance_metric ** 0.5)  # Non-linear weighting\n    perturb_jobs = critical_jobs[np.argsort(-dual_scores)[:len(critical_jobs)//2]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3483.66667,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Integrate machine learning-driven prioritization with dynamic objective weighting to guide decision-making and enhance solution quality in complex optimization landscapes.",
                    "Combine adaptive neighborhood search with local search enhancement to escape local optima while balancing multiple objectives for improved overall performance.",
                    "Leverage adaptive perturbation and neighborhood search strategies to escape local optima while maintaining a focus on balancing multiple objectives."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757945787.6697721
          }
     },
     {
          "algorithm": "The algorithm integrates machine learning-driven prioritization with adaptive perturbation and dynamic objective weighting to update the execution time matrix and select top jobs for perturbation, emphasizing a hybrid strategy that balances makespan minimization and resource utilization fairness.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_resource_utilization_fairness(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        avg_utilization = np.mean(machine_times)\n        fairness = np.sum(np.abs(machine_times - avg_utilization))\n        return fairness\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_impact_scores = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_impact_scores[job] += machine_times[machine] / (matrix[job, machine] + 1e-6)  # Avoid division by zero\n        return np.argsort(-job_impact_scores)[:n//3]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            noise = np.random.uniform(-0.1, 0.1, size=m)  # Uniform perturbation\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and resource utilization fairness\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    fairness_score = calculate_resource_utilization_fairness(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs based on impact scores\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix with uniform perturbation\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb using hybrid scoring\n    hybrid_scores = np.sum(new_matrix[critical_jobs, :], axis=1) * fairness_score / (current_makespan + 1e-6)\n    perturb_jobs = critical_jobs[np.argsort(-hybrid_scores)[:len(critical_jobs)//2]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3484.66667,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Integrate machine learning-driven prioritization with dynamic objective weighting to guide decision-making and enhance solution quality in complex optimization landscapes.",
                    "Combine adaptive neighborhood search with local search enhancement to escape local optima while balancing multiple objectives for improved overall performance.",
                    "Leverage adaptive perturbation and neighborhood search strategies to escape local optima while maintaining a focus on balancing multiple objectives."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757945790.208606
          }
     },
     {
          "algorithm": "The algorithm integrates machine learning-driven prioritization with adaptive neighborhood search, employing dynamic objective weighting and hybrid perturbation strategies to update the execution time matrix and select top jobs for perturbation, balancing makespan minimization and machine utilization fairness.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_machine_utilization(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return np.array(machine_times) / np.sum(machine_times)\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_impact = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_impact[job] += machine_times[machine] / (machine + 1)  # Weighted impact by machine order\n        return np.argsort(-job_impact)[:n//3]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            noise = np.random.uniform(-0.1, 0.1, size=m)  # Uniform perturbation for diversity\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and machine utilization\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    machine_utilization = calculate_machine_utilization(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs based on weighted machine impact\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix with uniform perturbation\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb using hybrid scoring\n    hybrid_scores = np.sum(new_matrix[critical_jobs, :], axis=1) * (1 + np.std(machine_utilization))\n    perturb_jobs = critical_jobs[np.argsort(-hybrid_scores)[:len(critical_jobs)//2]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3485.33333,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Integrate machine learning-driven prioritization with dynamic objective weighting to guide decision-making and enhance solution quality in complex optimization landscapes.",
                    "Combine adaptive neighborhood search with local search enhancement to escape local optima while balancing multiple objectives for improved overall performance.",
                    "Leverage adaptive perturbation and neighborhood search strategies to escape local optima while maintaining a focus on balancing multiple objectives."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757945695.042439
          }
     },
     {
          "algorithm": "Leverage a hybrid strategy combining adversarial perturbation with reinforcement learning-inspired exploration to dynamically update the matrix and prioritize jobs for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    # Backbone idea: Both algorithms focus on identifying critical jobs and perturbing execution times to escape local optima while balancing objectives like makespan and load balance.\n    # New algorithm: {Leverage a hybrid strategy combining adversarial perturbation with reinforcement learning-inspired exploration to dynamically update the matrix and prioritize jobs for perturbation.}\n    \n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def adversarial_perturbation(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            adversarial_noise = np.random.normal(0, 0.1, size=m)  # Gaussian noise for adversarial effect\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + adversarial_noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_impact_scores = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_impact_scores[job] += np.log1p(machine_times[machine])  # Logarithmic emphasis on impact\n        return np.argsort(-job_impact_scores)[:n//3]\n    \n    def reinforcement_exploration(matrix, critical_jobs):\n        exploration_scores = np.sum(matrix[critical_jobs, :], axis=1) * np.random.uniform(0.8, 1.2, size=len(critical_jobs))  # Exploration factor\n        return critical_jobs[np.argsort(-exploration_scores)[:len(critical_jobs)//2]]\n    \n    # Step 1: Calculate current makespan\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    \n    # Step 2: Identify critical jobs based on adversarial impact scoring\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix using adversarial perturbation\n    new_matrix = adversarial_perturbation(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb using reinforcement-inspired exploration\n    perturb_jobs = reinforcement_exploration(new_matrix, critical_jobs)\n    \n    return new_matrix, perturb_jobs",
          "objective": 3486.0,
          "other_inf": null,
          "metadata": {
               "operator": "e2",
               "wisdom_tips": [
                    "Combine machine learning-driven guidance with dynamic weighting of objectives to adaptively refine decision-making and enhance solution quality.",
                    "Integrate local search enhancements with global optimization strategies to escape local optima while preserving solution feasibility and efficiency.",
                    "Combine machine learning-driven guidance with dynamic weighting of objectives to adaptively refine solution quality and balance competing goals in real-time."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757946276.269655
          }
     },
     {
          "algorithm": "The algorithm employs a hybrid meta-heuristic strategy combining adaptive perturbation with machine learning-driven job prioritization, dynamically adjusting scoring parameters using non-linear weighting and surrogate objectives to guide exploration toward minimizing makespan while promoting load balance diversity.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_load_balance(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        avg_load = sum(machine_times) / m\n        return sum((t - avg_load)**2 for t in machine_times)\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_contributions = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_contributions[job] += np.log1p(machine_times[machine])  # Logarithmic emphasis on contributions\n        return np.argsort(-job_contributions)[:n//4]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            noise = np.random.normal(0, 0.1, size=m)  # Gaussian perturbation with symmetric bounds\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and load balance metric\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    load_balance_metric = calculate_load_balance(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs contributing to bottlenecks\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix with Gaussian perturbation\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb based on adaptive dual-objective scoring\n    dual_scores = (np.sum(new_matrix[critical_jobs, :], axis=1) ** 2.0) + (np.sqrt(load_balance_metric) ** 1.2)  # Non-linear weighting\n    perturb_jobs = critical_jobs[np.argsort(-dual_scores)[:len(critical_jobs)//3]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3486.66667,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features",
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757946666.383969
          }
     },
     {
          "algorithm": "The new algorithm integrates dynamic neighborhood search with non-linear adaptive weighting of objectives and hybrid machine-learning-driven job prioritization to iteratively refine the execution time matrix and select jobs for perturbation.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_load_balance(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        avg_load = sum(machine_times) / m\n        return sum((t - avg_load)**2 for t in machine_times)\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_contributions = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_contributions[job] += np.exp(machine_times[machine] / (np.mean(matrix[job, :]) + 1e-6))  # Exponential emphasis\n        return np.argsort(-job_contributions)[:n//4]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            noise = np.random.normal(0, 0.1, size=m)  # Gaussian perturbation with symmetric bounds\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] + noise * new_matrix[job, :], 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and load balance metric\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    load_balance_metric = calculate_load_balance(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs contributing to bottlenecks\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix with Gaussian perturbation\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb based on adaptive dual-objective scoring\n    dual_scores = (np.sum(new_matrix[critical_jobs, :], axis=1) ** 2.0) * np.log1p(load_balance_metric)  # Non-linear weighting with logarithmic scaling\n    perturb_jobs = critical_jobs[np.argsort(-dual_scores)[:len(critical_jobs)//3]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3488.66667,
          "other_inf": null,
          "metadata": {
               "operator": "m2",
               "wisdom_tips": [
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features",
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757946765.63167
          }
     },
     {
          "algorithm": "The new algorithm integrates machine learning-driven guidance with hybrid local-global perturbation strategies, dynamically balancing makespan minimization and resource utilization improvement through non-linear adaptive weighting.",
          "code": "import numpy as np\n\ndef get_matrix_and_jobs(current_sequence, time_matrix, m, n):\n    def calculate_makespan(sequence, matrix, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        return max(machine_times)\n    \n    def calculate_resource_utilization(matrix, sequence, m):\n        machine_times = [0] * m\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n        total_time = sum(machine_times)\n        return total_time / (m * max(machine_times)) if max(machine_times) > 0 else 0\n    \n    def identify_critical_jobs(matrix, sequence, m):\n        machine_times = [0] * m\n        job_impact_scores = np.zeros(n)\n        for job in sequence:\n            for machine in range(m):\n                if machine == 0:\n                    machine_times[machine] += matrix[job, machine]\n                else:\n                    machine_times[machine] = max(machine_times[machine], machine_times[machine - 1]) + matrix[job, machine]\n                job_impact_scores[job] += np.log1p(machine_times[machine])  # Logarithmic emphasis on cumulative impact\n        return np.argsort(-job_impact_scores)[:n//4]\n    \n    def update_time_matrix(matrix, critical_jobs):\n        new_matrix = matrix.copy()\n        for job in critical_jobs:\n            global_perturbation = np.random.normal(1.0, 0.1, size=m)  # Gaussian perturbation for global exploration\n            local_perturbation = np.random.uniform(0.95, 1.05, size=m)  # Uniform perturbation for local refinement\n            combined_perturbation = global_perturbation * local_perturbation\n            new_matrix[job, :] = np.maximum(new_matrix[job, :] * combined_perturbation, 0)\n        return new_matrix\n    \n    # Step 1: Calculate current makespan and resource utilization\n    current_makespan = calculate_makespan(current_sequence, time_matrix, m)\n    resource_utilization = calculate_resource_utilization(time_matrix, current_sequence, m)\n    \n    # Step 2: Identify critical jobs based on cumulative impact scores\n    critical_jobs = identify_critical_jobs(time_matrix, current_sequence, m)\n    \n    # Step 3: Update execution time matrix using hybrid perturbation strategy\n    new_matrix = update_time_matrix(time_matrix, critical_jobs)\n    \n    # Step 4: Select top jobs to perturb based on adaptive dual-objective scoring\n    dual_scores = (np.sum(new_matrix[critical_jobs, :], axis=1) ** 1.2) + (resource_utilization ** 2)  # Non-linear weighting\n    perturb_jobs = critical_jobs[np.argsort(-dual_scores)[:len(critical_jobs)//2]]\n    \n    return new_matrix, perturb_jobs",
          "objective": 3489.33333,
          "other_inf": null,
          "metadata": {
               "operator": "e2",
               "wisdom_tips": [
                    "Combine machine learning-driven guidance with dynamic weighting of objectives to adaptively refine decision-making and enhance solution quality.",
                    "Integrate local search enhancements with global optimization strategies to escape local optima while preserving solution feasibility and efficiency.",
                    "Combine machine learning-driven guidance with dynamic weighting of objectives to adaptively refine solution quality and balance competing goals in real-time."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757946374.545782
          }
     }
]