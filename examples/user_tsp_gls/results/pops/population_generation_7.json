[
     {
          "algorithm": "```",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Simplified entropy-driven penalty mechanism\n    edge_usage_prob = edge_n_used / (np.sum(edge_n_used) + 1e-8)\n    edge_entropy = -edge_usage_prob * np.log(edge_usage_prob + 1e-8)\n    normalized_entropy = edge_entropy / (np.max(edge_entropy) + 1e-8)\n    \n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        entropy_penalty = 1 - normalized_entropy[u, v]\n        updated_edge_distance[u, v] += entropy_penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Simplified topology-aware stochastic scaling\n    global_entropy = np.mean(normalized_entropy)\n    if global_entropy < 0.5:\n        stochastic_perturbation = np.random.uniform(0, 0.1, (num_nodes, num_nodes))\n        updated_edge_distance += stochastic_perturbation\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.1522,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Leverage entropy-driven mechanisms and cumulative frequency adjustments to preserve solution diversity and enhance convergence efficiency.",
                    "Leverage entropy-driven strategies and adaptive scaling to maintain solution diversity and enhance the robustness of the optimization process.",
                    "Leverage entropy-driven and topology-aware strategies to iteratively refine the search space for improved global optimization."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757181951.39392
          }
     },
     {
          "algorithm": "Design a hybrid meta-heuristic that integrates topology-aware penalties, stochastic perturbations with adaptive scaling, and cumulative frequency balancing to iteratively reshape the search landscape while enhancing exploration and exploitation through non-linear feedback mechanisms.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization\n    topology_penalty_factor = 1.5\n    stochastic_scale_min, stochastic_scale_max = 0.1, 0.9\n    frequency_balance_weight = 0.6\n    \n    # Compute topology-aware penalties based on global connectivity\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        global_connectivity = np.sum(edge_n_used[u, :]) + np.sum(edge_n_used[v, :])\n        penalty = topology_penalty_factor * (1 + np.exp(-global_connectivity / (np.mean(edge_n_used) + 1e-8)))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Apply stochastic perturbations with adaptive scaling\n    stochastic_scale = stochastic_scale_min + (stochastic_scale_max - stochastic_scale_min) * np.random.rand(num_nodes, num_nodes)\n    stochastic_perturbation = stochastic_scale * (np.max(edge_n_used) - edge_n_used) / (np.max(edge_n_used) + 1e-8)\n    updated_edge_distance += stochastic_perturbation\n    \n    # Introduce cumulative frequency balancing adjustments\n    frequency_balance = frequency_balance_weight * (edge_n_used - np.mean(edge_n_used)) / (np.std(edge_n_used) + 1e-8)\n    frequency_balance = np.clip(frequency_balance, -np.inf, 0)  # Ensure only downward adjustments\n    updated_edge_distance += frequency_balance\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.15311,
          "other_inf": null,
          "metadata": {
               "operator": "m1",
               "wisdom_tips": [
                    "Introduce topology-aware penalties to dynamically reshape the search landscape, ensuring decisions reflect both local structure and global connectivity.",
                    "Incorporate stochastic perturbations with adaptive scaling to balance exploration and exploitation, enhancing robustness across diverse problem instances.",
                    "Integrate dynamic penalties and adaptive scaling to reshape the search landscape iteratively, enhancing both exploration and exploitation."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757181137.06735
          }
     },
     {
          "algorithm": "A hybrid strategy combining entropy-driven edge penalties and topology-aware stochastic scaling to reshape the search space dynamically while preserving solution diversity.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization for hybrid strategy\n    entropy_penalty_weight = 0.7\n    stochastic_scaling_factor = 0.2\n    global_entropy_threshold = 0.5\n    \n    # Compute entropy-based penalties to discourage overused edges\n    edge_usage_prob = edge_n_used / (np.sum(edge_n_used) + 1e-8)\n    edge_entropy = -edge_usage_prob * np.log(edge_usage_prob + 1e-8)\n    normalized_entropy = edge_entropy / (np.max(edge_entropy) + 1e-8)\n    \n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        entropy_penalty = entropy_penalty_weight * (1 - normalized_entropy[u, v])\n        updated_edge_distance[u, v] += entropy_penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Apply topology-aware stochastic scaling based on global entropy\n    global_entropy = np.mean(normalized_entropy)\n    if global_entropy < global_entropy_threshold:\n        stochastic_perturbation = np.random.normal(0, stochastic_scaling_factor, (num_nodes, num_nodes))\n        stochastic_perturbation = np.where(stochastic_perturbation > 0, stochastic_perturbation, 0)\n        updated_edge_distance += stochastic_perturbation\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.16825,
          "other_inf": null,
          "metadata": {
               "operator": "e1",
               "wisdom_tips": [
                    "Integrate topology-aware feedback to dynamically reshape the search space and enhance exploration-exploitation trade-offs.",
                    "Leverage stochastic perturbations with adaptive scaling to maintain diversity and adaptability in solution refinement.",
                    "Leverage entropy-driven or stochastic perturbations to enhance global search capabilities while preserving structural integrity in solution refinement."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757181685.049485
          }
     },
     {
          "algorithm": "```",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Simplified parameter initialization\n    topology_penalty_weight = 0.5\n    smoothing_factor = 0.1\n    \n    # Simplified topology-aware penalties based on local optimal tour\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        penalty = topology_penalty_weight * (1 + np.exp(-edge_n_used[u, v]))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Simplified stochastic perturbations with adaptive scaling\n    gradient_perturbation = np.random.uniform(-smoothing_factor, smoothing_factor, (num_nodes, num_nodes))\n    updated_edge_distance += gradient_perturbation\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.21461,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features",
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757180120.721326
          }
     },
     {
          "algorithm": "Design a hybrid meta-heuristic that combines topology-aware penalties, stochastic perturbations with adaptive scaling, and edge frequency normalization to iteratively reshape the search landscape while balancing exploration and exploitation.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization\n    topology_penalty_factor = 1.5\n    stochastic_scale = 0.8\n    normalization_weight = 0.6\n    \n    # Compute topology-aware penalties based on local optimal tour\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        penalty = topology_penalty_factor * (1 + np.exp(-edge_n_used[u, v] / (np.mean(edge_n_used) + 1e-8)))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Apply stochastic perturbations with adaptive scaling\n    stochastic_perturbation = stochastic_scale * np.random.uniform(0.5, 1.5, size=(num_nodes, num_nodes))\n    stochastic_perturbation = np.triu(stochastic_perturbation) + np.triu(stochastic_perturbation, 1).T\n    updated_edge_distance *= stochastic_perturbation\n    \n    # Introduce edge frequency normalization\n    normalized_frequencies = normalization_weight * (edge_n_used / (np.max(edge_n_used) + 1e-8))\n    updated_edge_distance -= normalized_frequencies\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.23271,
          "other_inf": null,
          "metadata": {
               "operator": "m1",
               "wisdom_tips": [
                    "Introduce topology-aware penalties to dynamically reshape the search landscape, ensuring decisions reflect both local structure and global connectivity.",
                    "Incorporate stochastic perturbations with adaptive scaling to balance exploration and exploitation, enhancing robustness across diverse problem instances.",
                    "Integrate dynamic penalties and adaptive scaling to reshape the search landscape iteratively, enhancing both exploration and exploitation."
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757181137.073193
          }
     },
     {
          "algorithm": "Design a hybrid meta-heuristic that integrates chaotic dynamic penalties, frequency-driven edge smoothing, and adaptive structural reinforcement to iteratively reshape the search landscape while balancing exploration and exploitation through non-linear feedback mechanisms.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization\n    chaos_factor = 1.3\n    smoothing_weight = 0.5\n    reinforcement_weight = 0.7\n    \n    # Compute chaotic dynamic penalties based on local optimal tour\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        penalty = chaos_factor * (1 + np.sin(edge_n_used[u, v] / (np.pi + 1e-8)))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Apply frequency-driven edge smoothing\n    smoothing_factor = smoothing_weight * (1 - np.tanh(edge_n_used / (np.max(edge_n_used) + 1e-8)))\n    updated_edge_distance -= smoothing_factor\n    \n    # Introduce adaptive structural reinforcement\n    reinforcement = reinforcement_weight * np.log(1 + np.outer(np.mean(edge_n_used, axis=1), np.mean(edge_n_used, axis=0)))\n    reinforcement = np.clip(reinforcement, 0, None)  # Ensure non-negative adjustments\n    updated_edge_distance += reinforcement\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.25838,
          "other_inf": null,
          "metadata": {
               "operator": "e2",
               "wisdom_tips": [
                    "Integrate adaptive perturbation and biasing mechanisms to dynamically reshape the search landscape while preserving structural insights for guided exploration.",
                    "Leverage frequency-based feedback and chaos-inspired strategies to balance exploitation and exploration in evolving problem spaces.",
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757179532.033579
          }
     },
     {
          "algorithm": "Design a hybrid strategy combining entropy-driven exploration, topology-aware penalties, and stochastic gradient-inspired perturbations to dynamically reshape the edge distance matrix for enhanced global search capability.",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization\n    entropy_weight = 0.4\n    topology_penalty_weight = 0.3\n    gradient_perturbation_weight = 0.5\n    smoothing_factor = 0.1\n    \n    # Compute entropy-driven exploration adjustments\n    edge_probabilities = edge_n_used / (np.sum(edge_n_used) + 1e-8)\n    entropy = -np.sum(edge_probabilities * np.log(edge_probabilities + 1e-8))\n    entropy_adjustment = entropy_weight * (1 - entropy / np.log(num_nodes))\n    updated_edge_distance += entropy_adjustment * edge_distance\n    \n    # Add topology-aware penalties based on local optimal tour\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        penalty = topology_penalty_weight * (1 + np.exp(-edge_n_used[u, v]))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Introduce stochastic gradient-inspired perturbations\n    gradient_perturbation = gradient_perturbation_weight * np.random.randn(num_nodes, num_nodes)\n    gradient_perturbation = np.clip(gradient_perturbation, -smoothing_factor, smoothing_factor)\n    updated_edge_distance += gradient_perturbation\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.31112,
          "other_inf": null,
          "metadata": {
               "operator": "e1",
               "wisdom_tips": [
                    "Dynamically reshape the search landscape by integrating adaptive penalties and perturbations to balance exploration and exploitation effectively.",
                    "Leverage learned structural insights and frequency-based feedback to guide decision-making while maintaining diversity in solution exploration.",
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757179471.5882251
          }
     },
     {
          "algorithm": "```",
          "code": "import numpy as np\n\ndef update_edge_distance(edge_distance, local_opt_tour, edge_n_used):\n    num_nodes = edge_distance.shape[0]\n    updated_edge_distance = edge_distance.copy()\n    \n    # Parameter initialization\n    topology_penalty_weight = 0.3\n    smoothing_factor = 0.1\n    \n    # Add topology-aware penalties based on local optimal tour\n    for i in range(len(local_opt_tour) - 1):\n        u, v = local_opt_tour[i], local_opt_tour[i + 1]\n        penalty = topology_penalty_weight * (1 + np.exp(-edge_n_used[u, v]))\n        updated_edge_distance[u, v] += penalty\n        updated_edge_distance[v, u] = updated_edge_distance[u, v]\n    \n    # Introduce stochastic perturbations with simplified gradient-inspired noise\n    perturbation = np.random.uniform(-smoothing_factor, smoothing_factor, (num_nodes, num_nodes))\n    updated_edge_distance += perturbation\n    \n    # Ensure no negative distances\n    updated_edge_distance = np.maximum(updated_edge_distance, 0)\n    \n    return updated_edge_distance",
          "objective": 0.31318,
          "other_inf": null,
          "metadata": {
               "operator": "m3",
               "wisdom_tips": [
                    "Design adaptive hybrid meta-heuristics synergistically fusing multiple search paradigms and dynamically tune operator parameters based on search stage or problem features",
                    "Employ machine learning or pattern recognition to mine deep problem structures and optimal solution patterns then use learned insights to intelligently bias towards promising search regions or constructive choices",
                    "Explore objective function engineering by introducing auxiliary or surrogate objectives or by dynamically adjusting weights to reshape the search landscape aiding escape from local optima or guiding diverse exploration"
               ],
               "attention_focus": "experimenting with hybrid strategy combinations",
               "generation_tendency": "focus_exploration",
               "timestamp": 1757180120.721349
          }
     }
]